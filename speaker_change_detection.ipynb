{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa\n",
    "!pip install pyAudioAnalysis\n",
    "!pip install hmmlearn\n",
    "!pip install eyed3\n",
    "!pip install pydub\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from pyAudioAnalysis import audioSegmentation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract audio features\n",
    "def extract_audio_features(audio_file):\n",
    "    # Load audio file\n",
    "    audio_data, sr = librosa.load(audio_file)\n",
    "    \n",
    "    # Extract features using librosa\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=sr)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_data, sr=sr)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio_data, sr=sr)\n",
    "    \n",
    "    # Concatenate features\n",
    "    features = np.concatenate((mfccs, spectral_centroids, spectral_rolloff, chroma_stft), axis=0)\n",
    "    \n",
    "    return features.T\n",
    "\n",
    "# Function to detect speaker changes\n",
    "def detect_speaker_changes(audio_file):\n",
    "    # Extract audio features\n",
    "    features = extract_audio_features(audio_file)\n",
    "    \n",
    "    # Get an initial estimate of the number of speakers\n",
    "    n_speakers = initial_estimate_of_speakers(audio_file)\n",
    "    \n",
    "    # Perform speaker diarization using pyAudioAnalysis\n",
    "    speaker_segments = audioSegmentation.speaker_diarization(audio_file, n_speakers=n_speakers, mid_window=2.0, mid_step=1.0)\n",
    "    \n",
    "    return speaker_segments\n",
    "\n",
    "# Function to get an initial estimate of the number of speakers\n",
    "def initial_estimate_of_speakers(audio_file):\n",
    "    # Perform some initial analysis to estimate the number of speakers\n",
    "    # Here's a placeholder value of 2 for demonstration purposes\n",
    "    return 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Sample1KN.mp3 to Sample1KN.wav\n",
      "Converted Sample2EN.mp3 to Sample2EN.wav\n",
      "Converted sample3KN.mp3 to sample3KN.wav\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Function to convert MP3 to WAV\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    # Load MP3 file\n",
    "    audio = AudioSegment.from_mp3(mp3_file)\n",
    "    \n",
    "    # Export as WAV\n",
    "    audio.export(wav_file, format=\"wav\")\n",
    "\n",
    "# List of MP3 files to convert\n",
    "mp3_files = [\"Sample1KN.mp3\", \"Sample2EN.mp3\", \"sample3KN.mp3\"]\n",
    "\n",
    "# Convert each MP3 file to WAV\n",
    "for mp3_file in mp3_files:\n",
    "    wav_file = mp3_file.replace(\".mp3\", \".wav\")  # Change file extension to WAV\n",
    "    convert_mp3_to_wav(mp3_file, wav_file)\n",
    "    print(f\"Converted {mp3_file} to {wav_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting speaker changes in /home/project/SoftmaxSSL/Sample1KN.wav:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/project/anaconda3/envs/to19/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker segments: (array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1]), -1, -1)\n",
      "Detecting speaker changes in /home/project/SoftmaxSSL/Sample2EN.wav:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/project/anaconda3/envs/to19/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker segments: (array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), -1, -1)\n",
      "Detecting speaker changes in /home/project/SoftmaxSSL/sample3KN.wav:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/project/anaconda3/envs/to19/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker segments: (array([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1]), -1, -1)\n"
     ]
    }
   ],
   "source": [
    "# Audio file paths\n",
    "audio_files = [\"/home/project/SoftmaxSSL/Sample1KN.wav\", \"/home/project/SoftmaxSSL/Sample2EN.wav\", \"/home/project/SoftmaxSSL/sample3KN.wav\"]\n",
    "\n",
    "# Detect speaker changes for each audio file\n",
    "for audio_file in audio_files:\n",
    "    print(f\"Detecting speaker changes in {audio_file}:\")\n",
    "    speaker_segments = detect_speaker_changes(audio_file)\n",
    "    print(\"Speaker segments:\", speaker_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker changes in /home/project/SoftmaxSSL/Sample1KN.wav:\n",
      "Error: file not found or other I/O error. (DECODING FAILED)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/project/anaconda3/envs/to19/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/project/anaconda3/envs/to19/lib/python3.9/site-packages/pyAudioAnalysis/ShortTermFeatures.py:17: RuntimeWarning: Mean of empty slice.\n",
      "  sig_array_norm -= sig_array_norm.mean()\n",
      "/home/project/anaconda3/envs/to19/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m audio_file \u001b[38;5;129;01min\u001b[39;00m audio_files:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeaker changes in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mprint_speaker_changes_with_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m, in \u001b[0;36mprint_speaker_changes_with_time\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_speaker_changes_with_time\u001b[39m(audio_file):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Detect speaker changes\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     speaker_segments \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_speaker_changes\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Get audio duration\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     duration \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mget_duration(filename\u001b[38;5;241m=\u001b[39maudio_file)\n",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m, in \u001b[0;36mdetect_speaker_changes\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m      7\u001b[0m y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_file, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Detect speaker changes\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m speaker_segments \u001b[38;5;241m=\u001b[39m \u001b[43maudioSegmentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeaker_diarization\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m speaker_segments\n",
      "File \u001b[0;32m~/anaconda3/envs/to19/lib/python3.9/site-packages/pyAudioAnalysis/audioSegmentation.py:838\u001b[0m, in \u001b[0;36mspeaker_diarization\u001b[0;34m(filename, n_speakers, mid_window, mid_step, short_window, lda_dim, plot_res)\u001b[0m\n\u001b[1;32m    831\u001b[0m classifier_all, mean_all, std_all, class_names_all, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    832\u001b[0m     at\u001b[38;5;241m.\u001b[39mload_model(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm_rbf_speaker_10\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    833\u001b[0m classifier_fm, mean_fm, std_fm, class_names_fm, _, _, _, _,  _ \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    834\u001b[0m     at\u001b[38;5;241m.\u001b[39mload_model(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm_rbf_speaker_male_female\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    837\u001b[0m mid_feats, st_feats, a \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 838\u001b[0m     \u001b[43mmtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid_feature_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmid_window\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmid_step\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m mid_term_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((mid_feats\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(class_names_all) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    845\u001b[0m                               \u001b[38;5;28mlen\u001b[39m(class_names_fm), mid_feats\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mid_feats\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n",
      "File \u001b[0;32m~/anaconda3/envs/to19/lib/python3.9/site-packages/pyAudioAnalysis/MidTermFeatures.py:94\u001b[0m, in \u001b[0;36mmid_feature_extraction\u001b[0;34m(signal, sampling_rate, mid_window, mid_step, short_window, short_step)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmid_feature_extraction\u001b[39m(signal, sampling_rate, mid_window, mid_step,\n\u001b[1;32m     88\u001b[0m                            short_window, short_step):\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    Mid-term feature extraction\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     short_features, short_feature_names \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 94\u001b[0m         \u001b[43mShortTermFeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mshort_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshort_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     n_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     98\u001b[0m     n_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(short_features)\n",
      "File \u001b[0;32m~/anaconda3/envs/to19/lib/python3.9/site-packages/pyAudioAnalysis/ShortTermFeatures.py:570\u001b[0m, in \u001b[0;36mfeature_extraction\u001b[0;34m(signal, sampling_rate, window, step, deltas)\u001b[0m\n\u001b[1;32m    567\u001b[0m signal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdouble(signal)\n\u001b[1;32m    568\u001b[0m signal \u001b[38;5;241m=\u001b[39m signal \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m--> 570\u001b[0m signal \u001b[38;5;241m=\u001b[39m \u001b[43mdc_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m number_of_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(signal)  \u001b[38;5;66;03m# total number of samples\u001b[39;00m\n\u001b[1;32m    573\u001b[0m current_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/to19/lib/python3.9/site-packages/pyAudioAnalysis/ShortTermFeatures.py:18\u001b[0m, in \u001b[0;36mdc_normalize\u001b[0;34m(sig_array)\u001b[0m\n\u001b[1;32m     16\u001b[0m sig_array_norm \u001b[38;5;241m=\u001b[39m sig_array\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     17\u001b[0m sig_array_norm \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m sig_array_norm\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 18\u001b[0m sig_array_norm \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msig_array_norm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sig_array_norm\n",
      "File \u001b[0;32m~/anaconda3/envs/to19/lib/python3.9/site-packages/numpy/core/_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_maximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from pyAudioAnalysis import audioSegmentation\n",
    "\n",
    "# Function to detect speaker changes\n",
    "def detect_speaker_changes(audio_file):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    \n",
    "    # Detect speaker changes\n",
    "    speaker_segments = audioSegmentation.speaker_diarization(y, sr)\n",
    "    \n",
    "    return speaker_segments\n",
    "\n",
    "# Function to print speaker changes with time stamps\n",
    "def print_speaker_changes_with_time(audio_file):\n",
    "    # Detect speaker changes\n",
    "    speaker_segments = detect_speaker_changes(audio_file)\n",
    "    \n",
    "    # Get audio duration\n",
    "    duration = librosa.get_duration(filename=audio_file)\n",
    "    \n",
    "    # Calculate time stamps for each segment\n",
    "    time_per_segment = duration / len(speaker_segments)\n",
    "    \n",
    "    # Print speaker changes with time stamps\n",
    "    for i, segment in enumerate(speaker_segments):\n",
    "        start_time = i * time_per_segment\n",
    "        end_time = (i + 1) * time_per_segment\n",
    "        speaker_id = segment[0]\n",
    "        print(f\"At time {start_time:.2f}-{end_time:.2f} seconds, speaker {speaker_id} is speaking.\")\n",
    "\n",
    "# Audio file paths\n",
    "audio_files = [\"/home/project/SoftmaxSSL/Sample1KN.wav\", \n",
    "               \"/home/project/SoftmaxSSL/Sample2EN.wav\", \n",
    "               \"/home/project/SoftmaxSSL/sample3KN.wav\"]\n",
    "\n",
    "# Print speaker changes for each audio file\n",
    "for audio_file in audio_files:\n",
    "    print(f\"Speaker changes in {audio_file}:\")\n",
    "    print_speaker_changes_with_time(audio_file)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "to19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
